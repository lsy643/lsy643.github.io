## Serving Build

### Server

1. Build minimal dependency for running inference
   - Maybe this is a way to run use model from Tensorflow as a normal DLL

2. Build minimal dependency for running inference with gRPC

3. C++ minimal dependency and Python Pip package both for GPU and CPU version


### Client
1. C++ and Python Pip package for client
